summary(model.coldN)
# check that number of data points per variable does = 30
dat_model <- xtabs(~ manipulation + condition, data=getData(model.coldN))
print(dat_model)
# extract fixed effects from the model - take the lowest effect size from the model
tgi_effect <- fixef(model.coldN)["conditionwithin"]
f
# need to estimate minimum desired effect from the change in slope - considering values can range from 0-100, it might be simpler to think of these effect sizes as a proportion of 100 instead
# tgi_effect = -17.05 would perhaps leave an expected effect size of .17
# change the effect size to effect size of interest
fixef(model.cold)["manipulationTGI"] <- tgi_effect
# then run power analysis
powerSim(model.cold)
# first try this on just one, simple model. The effect of manipulation on cold rating, with ID as a random effect
model.cold <- lmer(cold ~ manipulation + condition + (1|ID),
data = df_phs)
summary(model.cold)
coef(model.cold)
xtabs(~ manipulation + condition, data=getData(model.coldN))
xtabs(~ manipulation + condition, data=getData(model.cold))
data = df_sum[df_sum$VAS == 'cold ,])
# first try this on just one, simple model. The effect of manipulation on cold rating, with ID as a random effect
model.cold <- lmer(rating ~ manipulation + condition + (1|ID),
data = df_sum[df_sum$VAS == 'cold' ,])
summary(model.cold)
# first try this on just one, simple model. The effect of manipulation on cold rating, with ID as a random effect
model.cold <- lmer(rating ~ manipulation + condition + cold_location +
(1|ID) + (1|procedure),
data = df_sum[df_sum$VAS == 'cold' ,])
summary(model.cold)
xtabs(~ manipulation + condition + cold_location, data=getData(model.cold))
# add more participants to the model, for simulation
model.coldN <- extend(model.cold, within = 'manipulation+condition?cold_location', n=100)
# add more participants to the model, for simulation
model.coldN <- extend(model.cold, within = 'manipulation+condition+cold_location', n=100)
summary(model.coldN)
# check that number of data points per variable does = 30
dat_model <- xtabs(~ manipulation + condition, data=getData(model.coldN))
print(dat_model)
# check that number of data points per variable does = 30
dat_model <- xtabs(~ manipulation + condition + cold_location, data=getData(model.coldN))
print(dat_model)
summary(model.coldN)
# extract fixed effects from the model - take the lowest effect size from the model
tgi_effect <- fixef(model.coldN)["cold_locationprox_caud"]
# need to estimate minimum desired effect from the change in slope - considering values can range from 0-100, it might be simpler to think of these effect sizes as a proportion of 100 instead
# tgi_effect = -17.05 would perhaps leave an expected effect size of .17
# change the effect size to effect size of interest
fixef(model.cold)["manipulationTGI"] <- tgi_effect
# then run power analysis
powerSim(model.cold)
# extract fixed effects from the model - take the lowest effect size from the model
tgi_effect <- fixef(model.coldN)["cold_locationprox_caud"]
# need to estimate minimum desired effect from the change in slope - considering values can range from 0-100, it might be simpler to think of these effect sizes as a proportion of 100 instead
# tgi_effect = -17.05 would perhaps leave an expected effect size of .17
# change the effect size to effect size of interest
fixef(model.coldN)["cold_locationprox_caud"] <- tgi_effect
# then run power analysis
powerSim(model.coldN)
# extract fixed effects from the model - take the lowest effect size from the model
tgi_effect <- fixef(model.coldN)["manipulationTGI"]
cond_effect <- fixef(model.coldN)["conditionwithin"]
cold_loc_effect <- fixef(model.coldN)["cold_locationprox_caud"]
# need to estimate minimum desired effect from the change in slope - considering values can range from 0-100, it might be simpler to think of these effect sizes as a proportion of 100 instead
# tgi_effect = -17.05 would perhaps leave an expected effect size of .17
# change the effect size to effect size of interest
fixef(model.coldN)["cold_locationprox_caud"] <- cold_loc_effect
# let's see if this works because it hasn't before
pc.cold <- powerCurve(model.coldN)
# check that number of data points per variable does = 30
dat_model <- xtabs(~ manipulation + condition + cold_location, data=getData(model.coldN))
print(dat_model)
# let's see if this works because it hasn't before
pc.cold <- powerCurve(cold.modelN, within='manipulation+condition+cold_location',
breaks=1:5:100))
# can run a power curve to determine the point of trade off between N observations and power
pc.cold <- powerCurve(cold.modelN, within='manipulation+condition+cold_location',
breaks= seq(0, 100, by = 10))
# can run a power curve to determine the point of trade off between N observations and power
pc.cold <- powerCurve(model.coldN, within='manipulation+condition+cold_location',
breaks= seq(0, 100, by = 10))
View(model.coldN)
print(pc.cold)
# First, let's try to add 30 observations per variable combination, which would mean N = 30
model.coldN <- extend(model.cold, within = 'manipulation+condition+cold_location', n=30)
summary(model.coldN)
# check that number of data points per variable does = 30
dat_model <- xtabs(~ manipulation + condition + cold_location, data=getData(model.coldN))
print(dat_model)
# extract fixed effects from the model - take the lowest effect size from the model
tgi_effect <- fixef(model.coldN)["manipulationTGI"]
cond_effect <- fixef(model.coldN)["conditionwithin"]
cold_loc_effect <- fixef(model.coldN)["cold_locationprox_caud"]
# need to estimate minimum desired effect from the change in slope - considering values can range from 0-100, it might be simpler to think of these effect sizes as a proportion of 100 instead
# tgi_effect = -17.05 would perhaps leave an expected effect size of .17
# change the effect size to effect size of interest
fixef(model.coldN)["cold_locationprox_caud"] <- cold_loc_effect
# then run power analysis
pwr.cold <- powerSim(model.coldN)
print(pwr.cold)
# can run a power curve to determine the point of trade off between N observations and power
pc.cold <- powerCurve(model.coldN, within='manipulation+condition+cold_location',
breaks= seq(0, 30, by = 3))
print(pc.cold)
plot(pc.cold) # a good visualisation :)
View(pc.cold)
# can run a power curve to determine the point of trade off between N observations and power
pc.cold <- powerCurve(model.coldN, within='manipulation+condition+cold_location',
breaks= seq(1, 30, by = 3))
print(pc.cold)
plot(pc.cold) # a good visualisation :)
plot(pc.cold) # a good visualisation :)
model.warm <- lmer(rating ~ manipulation + condition + cold_location +
(1|ID) + (1|procedure),
data = df_sum[df_sum$VAS == 'warm' ,])
model.warm <- lmer(rating ~ manipulation + condition + cold_location +
(1|ID) + (1|procedure),
data = df_sum[df_sum$VAS == 'warm' ,])
model.warm <- lmer(rating ~ manipulation + condition + cold_location +
(1|ID),
data = df_sum[df_sum$VAS == 'warm' ,])
summary(model.warm)
# using n050 here as expecting smaller effect sizes
model.warmN <- extend(model.warm, within = 'manipulation+condition+cold_location', n=50)
# extracting effect sizes from the extended model
tgi_effect <- fixef(model.warmN)["manipulationTGI"]
cond_effect <- fixef(model.warmN)["conditionwithin"]
cold_loc_effect <- fixef(model.warmsN)["cold_locationprox_caud"]
cold_loc_effect <- fixef(model.warmN)["cold_locationprox_caud"]
# add smallest effect size - same as cold model
fixef(model.coldN)["cold_locationprox_caud"] <- cold_loc_effect
# then run power analysis
pwr.warm <- powerSim(model.coldN)
print(pwr.warm)
# can run a power curve to determine the point of trade off between N observations and power
pc.warm <- powerCurve(model.warmN, within='manipulation+condition+cold_location',
breaks= seq(1, 50, by = 5))
# then run power analysis
pwr.warm <- powerSim(model.warmN)
# using n050 here as expecting smaller effect sizes
model.warmN <- extend(model.warm, within = 'manipulation+condition+cold_location', n=50)
# extracting effect sizes from the extended model
tgi_effect <- fixef(model.warmN)["manipulationTGI"]
cond_effect <- fixef(model.warmN)["conditionwithin"]
cold_loc_effect <- fixef(model.warmN)["cold_locationprox_caud"]
# add smallest effect size - same as cold model
fixef(model.coldN)["cold_locationprox_caud"] <- cold_loc_effect
# then run power analysis
pwr.warm <- powerSim(model.warmN)
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(simr)
# using n050 here as expecting smaller effect sizes
model.warmN <- extend(model.warm, within = 'manipulation+condition+cold_location', n=50)
# extracting effect sizes from the extended model
tgi_effect <- fixef(model.warmN)["manipulationTGI"]
cond_effect <- fixef(model.warmN)["conditionwithin"]
cold_loc_effect <- fixef(model.warmN)["cold_locationprox_caud"]
# add smallest effect size - same as cold model
fixef(model.coldN)["cold_locationprox_caud"] <- cold_loc_effect
# then run power analysis
pwr.warm <- powerSim(model.warmN)
View(model.warm)
View(model.warm)
print(pwr.warm)
# can run a power curve to determine the point of trade off between N observations and power
pc.warm <- powerCurve(model.warmN, within='manipulation+condition+cold_location',
breaks= seq(1, 50, by = 5))
print(pc.warm)
rm(list=ls())
install.packages('TMB', type = 'source')
install.packages("TMB", type = "source")
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(simr)
library(broom)
library(brms)
library(modelsummary)
library(tibble)
library(DHARMa)
library(glmmTMB)
library(reshape2)
set.seed(1234)  # Make everything reproducible
# Define the goodness-of-fit stats to include in modelsummary()
gof_stuff <- tribble(
~raw, ~clean, ~fmt,
"nobs", "N", 0,
"r.squared", "R²", 3
)
# setting working directory
datPath <- '/Users/au706616/Documents/Experiments/SPINALTGI/Raw/'
knitr::opts_knit$set(root.dir = datPath)
# import compiled data
df <- read.csv('STGI_compiled-data.csv')
# need to recode levels for cold_probe to reduce number of levels from 4 to 2
df$cold_location[df$cold_probe == 'distal'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'rostral'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'proximal'] <- 'prox_caud'
df$cold_location[df$cold_probe == 'caudal'] <- 'prox_caud'
df$cold_location <- as.factor(df$cold_location)
# reshape data so that there is one rating column per participant, with a VAS column = type of rating
df_VAS <- melt(df, measure.vars= c("VAScold", "VASwarm","VASburning"),
id.vars=c("ID","trial_n","manipulation","procedure",
"trial_type","arm","condition","cold_location"),
variable.name = 'VAS', value.name = 'rating')
# rename the VAS ratings
df_VAS <- df_VAS %>%
mutate(VAS = revalue(VAS, c("VAScold" = "cold",
"VASwarm" = "warm",
"VASburning" = "burning")))
library(tidyverse)
# import compiled data
df <- read.csv('STGI_compiled-data.csv')
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(simr)
library(broom)
library(brms)
library(modelsummary)
library(tibble)
library(DHARMa)
library(glmmTMB)
library(reshape2)
library(tidyverse)
set.seed(1234)  # Make everything reproducible
# Define the goodness-of-fit stats to include in modelsummary()
gof_stuff <- tribble(
~raw, ~clean, ~fmt,
"nobs", "N", 0,
"r.squared", "R²", 3
)
# setting working directory
datPath <- '/Users/au706616/Documents/Experiments/SPINALTGI/Raw/'
knitr::opts_knit$set(root.dir = datPath)
# import compiled data
df <- read.csv('STGI_compiled-data.csv')
# need to recode levels for cold_probe to reduce number of levels from 4 to 2
df$cold_location[df$cold_probe == 'distal'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'rostral'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'proximal'] <- 'prox_caud'
df$cold_location[df$cold_probe == 'caudal'] <- 'prox_caud'
df$cold_location <- as.factor(df$cold_location)
# reshape data so that there is one rating column per participant, with a VAS column = type of rating
df_VAS <- melt(df, measure.vars= c("VAScold", "VASwarm","VASburning"),
id.vars=c("ID","trial_n","manipulation","procedure",
"trial_type","arm","condition","cold_location"),
variable.name = 'VAS', value.name = 'rating')
# rename the VAS ratings
df_VAS <- df_VAS %>%
mutate(VAS = revalue(VAS, c("VAScold" = "cold",
"VASwarm" = "warm",
"VASburning" = "burning")))
library(dplyr)
# import compiled data
df <- read.csv('STGI_compiled-data.csv')
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(simr)
library(broom)
library(brms)
library(modelsummary)
library(tibble)
library(DHARMa)
library(glmmTMB)
library(reshape2)
library(dplyr)
set.seed(1234)  # Make everything reproducible
# Define the goodness-of-fit stats to include in modelsummary()
gof_stuff <- tribble(
~raw, ~clean, ~fmt,
"nobs", "N", 0,
"r.squared", "R²", 3
)
# setting working directory
datPath <- '/Users/au706616/Documents/Experiments/SPINALTGI/Raw/'
knitr::opts_knit$set(root.dir = datPath)
# import compiled data
df <- read.csv('STGI_compiled-data.csv')
# need to recode levels for cold_probe to reduce number of levels from 4 to 2
df$cold_location[df$cold_probe == 'distal'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'rostral'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'proximal'] <- 'prox_caud'
df$cold_location[df$cold_probe == 'caudal'] <- 'prox_caud'
df$cold_location <- as.factor(df$cold_location)
# reshape data so that there is one rating column per participant, with a VAS column = type of rating
df_VAS <- melt(df, measure.vars= c("VAScold", "VASwarm","VASburning"),
id.vars=c("ID","trial_n","manipulation","procedure",
"trial_type","arm","condition","cold_location"),
variable.name = 'VAS', value.name = 'rating')
# rename the VAS ratings
df_VAS <- df_VAS %>%
mutate(VAS = revalue(VAS, c("VAScold" = "cold",
"VASwarm" = "warm",
"VASburning" = "burning")))
library(plyr)
knitr::opts_knit$set(root.dir = datPath)
# import compiled data
df <- read.csv('STGI_compiled-data.csv')
# need to recode levels for cold_probe to reduce number of levels from 4 to 2
df$cold_location[df$cold_probe == 'distal'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'rostral'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'proximal'] <- 'prox_caud'
df$cold_location[df$cold_probe == 'caudal'] <- 'prox_caud'
df$cold_location <- as.factor(df$cold_location)
# reshape data so that there is one rating column per participant, with a VAS column = type of rating
df_VAS <- melt(df, measure.vars= c("VAScold", "VASwarm","VASburning"),
id.vars=c("ID","trial_n","manipulation","procedure",
"trial_type","arm","condition","cold_location"),
variable.name = 'VAS', value.name = 'rating')
# rename the VAS ratings
df_VAS <- df_VAS %>%
mutate(VAS = revalue(VAS, c("VAScold" = "cold",
"VASwarm" = "warm",
"VASburning" = "burning")))
# to run zero inflated regressions need to make sure no values = 100, as cannot model them, so simply minus a very small fraction from those values
df_VAS$beta <- ifelse(df_VAS$rating==100, df_VAS$beta-0.0001, df_VAS$beta <- df_VAS$rating)
# transform variables into proportions (aka divide by 100), this makes the effect size estimates more logical
df_VAS$beta <- df_VAS$beta/100
df_VAS$ID <- factor(df_VAS$ID)
# Summarise data per rating, per participant
df_sum <- aggregate(rating~ID*manipulation*condition*cold_location*procedure*VAS,
median, data = df)
# Summarise data per rating, per participant
df_sum <- aggregate(rating~ID*manipulation*condition*cold_location*procedure*VAS,
median, data = df_VAS)
View(df_sum)
View(df_VAS)
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,])
# then model warm VAS
model.warm = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'warm' ,])
# model summaries
summary(model.cold)
summary(model.warm)
# cold assumption
model.cold.assmup <- simulateResiduals(model.cold)
plot(model.cold.assmup)
# warm assumption
model.warm.assump <- simulateResiduals(model.warm)
plot(model.warm.assump)
# First, let's try to add 30 observations per variable combination, which would mean N = 30
model.cold.ex <- extend(model.cold, within = 'manipulation+condition+cold_location', n=30)
summary(model.cold.ex)
help("glmmTMB")
?glmmTMB::beta_family
ggplot(data = df_VAS) +
geom_density(beta, fill = VAS)
ggplot(data = df_VAS) +
geom_density(aes(beta, fill = VAS))
ggplot(data = df_VAS) +
geom_density(aes(beta, fill = VAS), alpha = .5)
# cold assumption
model.cold.assmup <- simulateResiduals(model.cold, n = 1000)
plot(model.cold.assmup)
# warm assumption
model.warm.assump <- simulateResiduals(model.warm, n = 1000)
plot(model.warm.assump)
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::betabinomial(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,])
# then model warm VAS
model.warm = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::betabinomial(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'warm' ,])
# model summaries
summary(model.cold)
summary(model.warm)
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,])
# model summaries
summary(model.cold)
ggplot(data = df_VAS) +
geom_density(aes(beta, fill = VAS), alpha = .5) +
facet_wrap(~manipulation)
ggplot(data = df_VAS) +
geom_density(aes(beta, fill = manipulation), alpha = .5) +
facet_wrap(~VAS)
fixef(model.cold)
fixef(model.cold['manipulationTGI'])
fixef(model.cold[1])
fixef(model.cold)
test <- fixef(model.cold)
View(test)
fixef(model.cold.cond)
fixef(model.cold['cond'])
fixef(model.cold)['cond']
fixef(model.cold)['cond'][1]
fixef(model.cold)['cond','manipulationTGI']
test <- fixef(model.cold)['cond','manipulationTGI']
test <- fixef(model.cold)['cond']
View(test)
test(cond)['manipulationTGI']
test['manipulationTGI']
test['cond']
test['cond' , 1]
class(test)
test[['manipulationTGI']]
test['cond'['manipulationTGI']]
test[['cond']]
test['manipulationTGI']
test['conditionwithin']
test['cond'(1)]
test['cond'[c(1)]
]
test['cond'[c(1,3)]
]
test['cond'[c(2,1)]]
test[[1]][[3]]
test[['cond']][['manipulationTGI']]
test <- fixef(model.cold)[['cond']][['manipulationTGI']]
test
# First, let's try to add 30 observations per variable combination, which would mean N = 30
model.cold.ex <- extend(model.cold, within = 'manipulation+condition+cold_location', n=30)
summary(model.cold.ex)
# check that number of data points per variable does = 30
dat_model <- xtabs(~ manipulation + condition + cold_location, data=getData(model.cold.ex))
print(dat_model)
# extract relevant effect sizes
tgi_effect <- fixef(model.cold.ex)[['cond']][['manipulationTGI']]
cond_effect <- fixef(model.cold.ex)[['cond']][['conditionwithin']]
cold_loc_effect <- fixef(model.cold.ex)[['cond']][['cold_locationprox_caud']]
cold_loc_effect
cond_effect <- fixef(model.cold.ex)[['cond']][['conditionwithin']]
cond_effect
# power analysis - using smallest effect size
fixef(model.cold.ex)[['cond']][['manipulationTGI']] <- cold_loc_effect
fixef(model.cold.ex)[['cond']][['manipulationTGI']]
# power curve
# can run a power curve to determine the point of trade off between N observations and power
pc.cold <- powerCurve(model.cold.ex, within='manipulation+condition+cold_location',
breaks= seq(1, 30, by = 3))
# power analysis - using smallest effect size
fixef(model.cold.ex)[['cond']][['manipulationTGI']] <- cold_loc_effect
fixef(model.cold.ex)[[1]][[2]]
# power analysis - using smallest effect size
fixef(model.cold.ex)[[1]][[2]] <- cold_loc_effect
View(model.cold.ex)
# power analysis - using smallest effect size
fixef(model.cold.ex) <- cold_loc_effect
# power analysis - using smallest effect size
fixef(model.cold.ex)[['cond']][['cold_locationprox_caud']] <- cold_loc_effect
# power analysis - using smallest effect size
fixef(model.cold.ex)[['cold_locationprox_caud']] <- cold_loc_effect
# First, let's try to add 30 observations per variable combination, which would mean N = 30
model.cold.ex <- extend(model.cold, within = 'manipulation+condition+cold_location', n=30)
# extract relevant effect sizes
tgi_effect <- fixef(model.cold.ex)[['cond']][['manipulationTGI']]
cond_effect <- fixef(model.cold.ex)[['cond']][['conditionwithin']]
cold_loc_effect <- fixef(model.cold.ex)[['cond']][['cold_locationprox_caud']]
# power analysis - using smallest effect size
fixef(model.cold.ex)[['cold_locationprox_caud']] <- cold_loc_effect
fixef(model.cold.ex)
fixef(model.cold.ex)['Conditional model:']
fixef(model.cold.ex)['Conditional model:']
fixef(model.cold.ex)['zero']
fixef(model.cold.ex)['cond']
fixef(model.cold.ex)['cond']['manipulationTGI']
fixef(model.cold.ex)['cond'][['manipulationTGI']]
fixef(model.cold.ex)[['cond']][['manipulationTGI']]
e <- fixef(model.cold.ex)[['cond']][['manipulationTGI']]
View(e)
# power analysis - using smallest effect size
fixef(model.cold.ex)[['cond']][['cold_locationprox_caud']] <- cold_loc_effect
pwr.cold <- powerSim(model.cold)
print(pwr.cold)
pwr.cold <- powerSim(model.cold.ex)
print(pwr.cold)
# power analysis - using smallest effect size
fixef(model.cold.ex)[['cond']][['cold_locationprox_caud']] <- .2
doTest(model.cold.ex, fixed("manipulationTGI", "lr"))
library(simr)
doTest(model.cold.ex, fixed("manipulationTGI", "lr"))
doTest(model.cold.ex, fixed("manipulationTGI", "z"))
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit)
# model summaries
summary(model.cold)
# warm assumption
model.warm.assump <- simulateResiduals(model.warm, n = 1000)
plot(model.warm.assump)
# then model warm VAS
model.warm = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'warm' ,])
summary(model.warm)
# warm assumption
model.warm.assump <- simulateResiduals(model.warm, n = 1000)
plot(model.warm.assump)
