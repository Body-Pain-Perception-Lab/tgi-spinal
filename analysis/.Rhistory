knitr::opts_knit$set(root.dir = datPath)
# import compiled data
df <- read.csv('STGI_compiled-data.csv')
# need to recode levels for cold_probe to reduce number of levels from 4 to 2
df$cold_location[df$cold_probe == 'distal'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'rostral'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'proximal'] <- 'prox_caud'
df$cold_location[df$cold_probe == 'caudal'] <- 'prox_caud'
df$cold_location <- as.factor(df$cold_location)
# reshape data so that there is one rating column per participant, with a VAS column = type of rating
df_VAS <- melt(df, measure.vars= c("VAScold", "VASwarm","VASburn"),
id.vars=c("ID","trial_n","manipulation","order",
"trial_type","arm","condition","cold_location"),
variable.name = 'VAS', value.name = 'rating')
# rename the VAS ratings
df_VAS <- df_VAS %>%
mutate(VAS = revalue(VAS, c("VAScold" = "cold",
"VASwarm" = "warm",
"VASburn" = "burn")))
# to run zero inflated regressions need to make sure no values = 100, as cannot model them, so simply minus a very small fraction from those values
df_VAS$beta <- ifelse(df_VAS$rating==100, df_VAS$beta-0.0001, df_VAS$beta <- df_VAS$rating)
# transform variables into proportions (aka divide by 100), this makes the effect size estimates more logical
df_VAS$beta <- df_VAS$beta/100
df_VAS$ID <- factor(df_VAS$ID)
# Summarise data per rating, per participant
df_sum <- aggregate(rating~ID*manipulation*condition*cold_location*order*VAS,
median, data = df_VAS)
ggplot(data = df_VAS) +
geom_density(aes(beta, fill = manipulation), alpha = .5) +
facet_wrap(~VAS) +
theme_classic()
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit)
# then model warm VAS
model.warm = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'warm' ,])
# model summaries
summary(model.cold)
summary(model.warm)
VarCorr(model.old)
VarCorr(model.cold)
fixef(model.cold)
test <- fixef(model.cold)
test[1]
test[2]
install.packages('BetaPASS')
library(BetaPASS)
helps(BetaPASS)
help(BetaPASS)
??BetaPASS
library(tidyverse)
## Beta Regression Power Analysis
## Simulations to assess statistical power given alpha, n, effect size
## Tyson S. Barrett
library(tidyverse)
library(betareg)
set.seed(84322)
## Population Model
pop <- 100000              ## provides the population size (arbitrary) - just want it big
n <- 400                   ## change this to what sample size we want to test
vars <- paste0("x", 1:10)
preds <- map(vars, ~data.frame(rnorm(pop, sd = 1)) %>% set_names(.x)) %>%
do.call("cbind", .)
data <- preds %>%
mutate(outcome = .04*preds$x1 + .04*preds$x2 + .04*preds$x1*preds$x2 + rbeta(pop, 2.1, 3.5)) %>%
mutate(outcome = case_when(outcome < 0 ~ 0,
TRUE ~ outcome)) %>%
mutate(outcome = outcome/max(outcome)) %>%
mutate(outcome = (outcome * (pop - 1) + .5) / pop) %>%
mutate(x1 = scale(x1),
x2 = scale(x2))
## rough estimate of partial correlation for x1
lm(scale(outcome) ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10,
data = data)
## Odds ratio effect size here
betareg::betareg(outcome ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10,
data = data) %>%
coef() %>%
exp()
## Start plot of the distribution of the outcome
plot(density(data$outcome), lwd = 2, col = "chartreuse3",
main = "Distribution of Outcome",
xlab = "Value of Outcome",
ylim=c(0, 2.5))
## Replications
replicates <- replicate(1000, {
d1 <- data[sample(1:pop, n), ]
lines(density(d1$outcome), col = alpha("dodgerblue3", .1))
## Population Effect Size
betareg::betareg(outcome ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10,
data = d1) %>%
summary() %>%
coef() %>%
.$mean
},
simplify = FALSE)
## Finish Plot
lines(density(data$outcome), lwd = 2, col = "chartreuse3")
## Assess power
replicates %>%
purrr::map(~data.frame(.x) %>%
rownames_to_column() %>%
set_names(c("var", "est", "se", "z", "p"))) %>%
do.call("rbind", .) %>%
data.frame %>%
filter(var %in% c("x1", "x2")) %>%
summarize(power = sum(p < .05)/2000)
## Interaction Effects
## rough estimate of partial correlation for x1
lm(scale(outcome) ~ x1 * x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10,
data = data)
replicates2 <- replicate(1000, {
d1 <- data[sample(1:pop, n), ]
## Population Effect Size
betareg::betareg(outcome ~ x1 * x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10,
data = d1) %>%
summary() %>%
coef() %>%
.$mean
},
simplify = FALSE)
replicates2 %>%
purrr::map(~data.frame(.x) %>%
rownames_to_column() %>%
set_names(c("var", "est", "se", "z", "p"))) %>%
do.call("rbind", .) %>%
data.frame %>%
filter(var %in% c("x1:x2")) %>%
summarize(power = sum(p < .05)/1000)
## Population Model
pop <- 100000              ## provides the population size (arbitrary) - just want it big
n <- 50                    ## change this to what sample size we want to test
vars <- paste0("x", 1:10)
rm(list= ls())
set.seed(84322)
## Population Model
pop <- 100000              ## provides the population size (arbitrary) - just want it big
n <- 50                    ## change this to what sample size we want to test
vars <- paste0("x", 1:10)
preds <- map(vars, ~data.frame(rnorm(pop, sd = 1)) %>% set_names(.x)) %>%
do.call("cbind", .)
View(preds)
data <- preds %>%
mutate(outcome = .04*preds$x1 + .04*preds$x2 + .04*preds$x1*preds$x2 + rbeta(pop, 2.1, 3.5)) %>%
mutate(outcome = case_when(outcome < 0 ~ 0,
TRUE ~ outcome)) %>%
mutate(outcome = outcome/max(outcome)) %>%
mutate(outcome = (outcome * (pop - 1) + .5) / pop) %>%
mutate(x1 = scale(x1),
x2 = scale(x2))
View(data)
rbeta(pop, 2.1, 3.5)
## rough estimate of partial correlation for x1
lm(scale(outcome) ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10,
data = data)
## Odds ratio effect size here
betareg::betareg(outcome ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10,
data = data) %>%
coef() %>%
exp()
betareg::betareg(outcome ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10,
data = data)
## Start plot of the distribution of the outcome
plot(density(data$outcome), lwd = 2, col = "chartreuse3",
main = "Distribution of Outcome",
xlab = "Value of Outcome",
ylim=c(0, 2.5))
## Replications
replicates <- replicate(1000, {
d1 <- data[sample(1:pop, n), ]
lines(density(d1$outcome), col = alpha("dodgerblue3", .1))
## Population Effect Size
betareg::betareg(outcome ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10,
data = d1) %>%
summary() %>%
coef() %>%
.$mean
},
simplify = FALSE)
d1 <- data[sample(1:pop, n), ]
View(d1)
df_VAS[sample(1:pop, n), ]
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(simr)
library(broom)
library(brms)
library(modelsummary)
library(tibble)
library(DHARMa)
library(glmmTMB)
library(reshape2)
library(tidyverse)
library(plyr)
library(betareg)
set.seed(1234)  # Make everything reproducible
# Define the goodness-of-fit stats to include in modelsummary()
gof_stuff <- tribble(
~raw, ~clean, ~fmt,
"nobs", "N", 0,
"r.squared", "R²", 3
)
# setting working directory
datPath <- '/Users/au706616/Documents/Experiments/SPINALTGI/Raw/'
knitr::opts_knit$set(root.dir = datPath)
# import compiled data
df <- read.csv('STGI_compiled-data.csv')
# need to recode levels for cold_probe to reduce number of levels from 4 to 2
df$cold_location[df$cold_probe == 'distal'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'rostral'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'proximal'] <- 'prox_caud'
df$cold_location[df$cold_probe == 'caudal'] <- 'prox_caud'
df$cold_location <- as.factor(df$cold_location)
# reshape data so that there is one rating column per participant, with a VAS column = type of rating
df_VAS <- melt(df, measure.vars= c("VAScold", "VASwarm","VASburn"),
id.vars=c("ID","trial_n","manipulation","order",
"trial_type","arm","condition","cold_location"),
variable.name = 'VAS', value.name = 'rating')
# rename the VAS ratings
df_VAS <- df_VAS %>%
mutate(VAS = revalue(VAS, c("VAScold" = "cold",
"VASwarm" = "warm",
"VASburn" = "burn")))
# to run zero inflated regressions need to make sure no values = 100, as cannot model them, so simply minus a very small fraction from those values
df_VAS$beta <- ifelse(df_VAS$rating==100, df_VAS$beta-0.0001, df_VAS$beta <- df_VAS$rating)
# transform variables into proportions (aka divide by 100), this makes the effect size estimates more logical
df_VAS$beta <- df_VAS$beta/100
df_VAS$ID <- factor(df_VAS$ID)
# Summarise data per rating, per participant
df_sum <- aggregate(rating~ID*manipulation*condition*cold_location*order*VAS,
median, data = df_VAS)
View(df_VAS)
df_VAS[sample(1:pop, n), ]
betareg::betareg(outcome ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10,
data = d1) %>%
summary() %>%
coef() %>%
.$mean
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit) %>%
summary() %>%
coef() %>%
.$mean
glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit) %>%
summary() %>%
coef() %>%
.$mean
glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
+                      (1|ID),
+                  family = glmmTMB::beta_family(),
+                  ziformula = ~1+manipulation,
+                  data = df_VAS[df_VAS$VAS == 'cold' ,],
+                  na.action = na.omit) %>%
+     summary() %>%
+     coef()
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit) %>%
summary() %>%
coef()
model.cold
model.cold$cond
model.cold$cond['manipulationTGI']
model.cold$cond[['manipulationTGI']]
model.cold$cond[1]
fixef(model.cold$cond)
fixef(model.cold$cond[1])
fixef(model.cold)
rm(list= ls())
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(simr)
library(broom)
library(brms)
library(modelsummary)
library(tibble)
library(DHARMa)
library(glmmTMB)
library(reshape2)
library(tidyverse)
library(plyr)
set.seed(1234)  # Make everything reproducible
# Define the goodness-of-fit stats to include in modelsummary()
gof_stuff <- tribble(
~raw, ~clean, ~fmt,
"nobs", "N", 0,
"r.squared", "R²", 3
)
# setting working directory
datPath <- '/Users/au706616/Documents/Experiments/SPINALTGI/Raw/'
knitr::opts_knit$set(root.dir = datPath)
# import compiled data
df <- read.csv('STGI_compiled-data.csv')
# need to recode levels for cold_probe to reduce number of levels from 4 to 2
df$cold_location[df$cold_probe == 'distal'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'rostral'] <- 'dist_rostr'
df$cold_location[df$cold_probe == 'proximal'] <- 'prox_caud'
df$cold_location[df$cold_probe == 'caudal'] <- 'prox_caud'
df$cold_location <- as.factor(df$cold_location)
# reshape data so that there is one rating column per participant, with a VAS column = type of rating
df_VAS <- melt(df, measure.vars= c("VAScold", "VASwarm","VASburn"),
id.vars=c("ID","trial_n","manipulation","order",
"trial_type","arm","condition","cold_location"),
variable.name = 'VAS', value.name = 'rating')
# rename the VAS ratings
df_VAS <- df_VAS %>%
mutate(VAS = revalue(VAS, c("VAScold" = "cold",
"VASwarm" = "warm",
"VASburn" = "burn")))
# to run zero inflated regressions need to make sure no values = 100, as cannot model them, so simply minus a very small fraction from those values
df_VAS$beta <- ifelse(df_VAS$rating==100, df_VAS$beta-0.0001, df_VAS$beta <- df_VAS$rating)
# transform variables into proportions (aka divide by 100), this makes the effect size estimates more logical
df_VAS$beta <- df_VAS$beta/100
df_VAS$ID <- factor(df_VAS$ID)
# Summarise data per rating, per participant
df_sum <- aggregate(rating~ID*manipulation*condition*cold_location*order*VAS,
median, data = df_VAS)
ggplot(data = df_VAS) +
geom_density(aes(beta, fill = manipulation), alpha = .5) +
facet_wrap(~VAS) +
theme_classic()
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit)
# then model warm VAS
model.warm = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'warm' ,])
# model summaries
summary(model.cold)
summary(model.warm)
model.cold$cond
coef(model.cold)
summary(coef(model.codl))
summary(coef(model.cold))
coef(model.cold$cond)
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit) %>%
summary()
model.cold
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit) %>%
summary() %>%
coef()
model.cold
model.cold$cond
model.cold$cond[2]
# then model warm VAS
model.warm = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'warm' ,]) %>%
summary() %>%
coef()
model.warm
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit)
model.cold %>% summary() %>% coef()
# Extract coefficients (effect sizes) of interest from pilot data model
modelc.coefs <- model.cold %>% summary() %>%
coef()
modelc.coefs
modelw.coefs <- model.warm %>% summary() %>%
coef()
# then model warm VAS
model.warm = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'warm' ,])
modelw.coefs <- model.warm %>% summary() %>%
coef()
# First, let's try to add 30 observations per variable combination, which would mean N = 30
model.cold.ex <- extend(model.cold, within = 'manipulation+condition+cold_location', n=30)
summary(model.cold.ex)
# extract relevant effect sizes
tgi_effect <- fixef(model.cold.ex)[['cond']][['manipulationTGI']]
tgi_effect
# power analysis - using smallest effect size
(model.cold.ex)[['cond']][['cold_locationprox_caud']] <- cold_loc_effect
fixef(model.cold)
fixef(modelc.coef)
fixef(modelc.coefs)
test <- fixef(model.cold)
View(Test)
View(test)
test <- fixef(model.cold$modelInfo)
test <- fixef(model.cold[cond])
test <- fixef(model.cold['cond'])
install.packages('mixedpower')
mixedpower(model.cold, df_VAS, fixed_effects, simvar,
steps, critical_value, n_sim = 1000,
SESOI = F, databased = T)
install_github("DejanDraschkow/mixedpower")
library(devtools)
install_github("DejanDraschkow/mixedpower")
install_github("DejanDraschkow/mixedpower")
mixedpower(model.cold, df_VAS, fixed_effects, simvar,
steps, critical_value, n_sim = 1000,
SESOI = F, databased = T)
library(mixedpower)
install.packages('nloptr')
install.packages("nloptr")
install.packages("nloptr")
install.packages("nloptr")
install.packages("nloptr")
install_github("DejanDraschkow/mixedpower")
library(devtools)
install_github("DejanDraschkow/mixedpower")
mixedpower(model.cold, df_VAS, fixed_effects, simvar,
steps, critical_value, n_sim = 1000,
SESOI = F, databased = T)
library(mixedpower)
mixedpower(model.cold, df_VAS, fixed_effects, simvar,
steps, critical_value, n_sim = 1000,
SESOI = F, databased = T)
powerC <- mixedpower::mixedpower(model = model.cold,  data = df_VAS, )
powerC <- mixedpower::mixedpower(model = model.cold,  data = df_VAS, fixed_effects = c('manipulation','condition','cold_location'), simvar = 'ID', steps = c(10,20,30,40), critical_value = 2)
class(df_VAS$ID)
df_VAS$ID <- as.numeric(df_VAS$ID)
powerC <- mixedpower::mixedpower(model = model.cold,  data = df_VAS, fixed_effects = c('manipulation','condition','cold_location'), simvar = 'ID', steps = c(10,20,30,40), critical_value = 2)
fitTMB(model.cold)
fixef.model.col
fixef.model.cold
fixef(model.cold)
library(lme4)
library(broom)
library(broom)
library(brms)
library(broom)
library(brms)
library(modelsummary)
library(tibble)
library(DHARMa)
library(glmmTMB)
library(reshape2)
library(tidyverse)
library(plyr)
library(betareg)
set.seed(1234)  # Make everything reproducible
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit) %>%
summary() %>%
coef() %>%
.$mean
# First model cold VAS
model.cold = glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID),
family = glmmTMB::beta_family(),
ziformula = ~1+manipulation,
data = df_VAS[df_VAS$VAS == 'cold' ,],
na.action = na.omit)
powerC <- mixedpower::mixedpower(model = model.cold,  data = df_VAS, fixed_effects = c('manipulation','condition','cold_location'), simvar = 'ID', steps = c(10,20,30,40), critical_value = 2)
fixef(model.cold)
f1 <- fixef(model.cold)
m1 <- glmmTMB::glmmTMB(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID), data = df_VAS[df_VAS$VAS == 'cold' ,])
m1
mixedpower(m1, data = df_VAS, fixed_effects = 'manipulation', simvar = 'ID', steps = c(10,20,30), critical_value = 2, n_sim = 10)
m1 <- lmer(beta ~ manipulation + condition + cold_location + trial_n +
(1|ID), data = df_VAS[df_VAS$VAS == 'cold' ,])
m1
mixedpower(m1, data = df_VAS, fixed_effects = 'manipulation', simvar = 'ID', steps = c(10,20,30), critical_value = 2, n_sim = 10)
mixedpower(m1, data = df_VAS, fixed_effects = 'manipulationTGI', simvar = 'ID', steps = c(10,20,30), critical_value = 2, n_sim = 10)
mixedpower(m1, data = df_VAS, fixed_effects = 'cold_location', simvar = 'ID', steps = c(10,20,30), critical_value = 2, n_sim = 10)
